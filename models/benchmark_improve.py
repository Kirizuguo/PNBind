"""
PNBind - å®Œå…¨æŒ‰ç…§è®ºæ–‡æ¶æ„å®ç°
ä¸¥æ ¼éµå¾ª Figure 1 çš„è®¾è®¡
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import PointGNNConv, global_mean_pool as gep


# ====================================================================
# åŸºç¡€æ¨¡å—ï¼ˆPointGNN çš„ MLPï¼‰
# ====================================================================

class mlp_h(nn.Module):
    """PointGNN ä¸­çš„ h_theta MLP"""
    def __init__(self, inputdim=1536, hiddendim=768, outputdim=1536, dropout=0.2):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(inputdim, hiddendim),
            nn.LayerNorm(hiddendim),
            nn.Dropout(dropout),
            nn.LeakyReLU(),
            nn.Linear(hiddendim, outputdim),
            nn.Dropout(dropout),
            nn.LeakyReLU()
        )

    def forward(self, x):
        return self.mlp(x)


class mlp_f(nn.Module):
    """PointGNN ä¸­çš„ f_theta MLP"""
    def __init__(self, inputdim=3072, hiddendim=1536, outputdim=1536, dropout=0.2):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(inputdim, hiddendim),
            nn.LayerNorm(hiddendim),
            nn.Dropout(dropout),
            nn.LeakyReLU(),
            nn.Linear(hiddendim, outputdim),
            nn.Dropout(dropout),
            nn.LeakyReLU()
        )

    def forward(self, x):
        return self.mlp(x)


class mlp_g(nn.Module):
    """PointGNN ä¸­çš„ g_theta MLP"""
    def __init__(self, inputdim=1536, hiddendim=1536, outputdim=1536, dropout=0.2):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(inputdim, hiddendim),
            nn.LayerNorm(hiddendim),
            nn.Dropout(dropout),
            nn.LeakyReLU(),
            nn.Linear(hiddendim, outputdim),
            nn.Dropout(dropout),
            nn.LeakyReLU()
        )

    def forward(self, x):
        return self.mlp(x)


# ====================================================================
# ğŸ”´ æ–°å¢ï¼šæ³¨æ„åŠ›èåˆæ¨¡å—
# ====================================================================

class AttentionFusion(nn.Module):
    """
    åŸºäºæ³¨æ„åŠ›çš„å¤šæ¨¡æ€ç‰¹å¾èåˆ
    
    æ›¿ä»£åŸæ¥çš„ç®€å• concat + MLP
    ä½¿ç”¨ multi-head attention è®©ä¸åŒæ¨¡æ€ç›¸äº’äº¤äº’
    
    å‚æ•°ï¼š
        input_dims: å„æ¨¡æ€çš„è¾“å…¥ç»´åº¦ [semantic_dim, geo_dim, rsa_dim]
        output_dim: è¾“å‡ºç»´åº¦
        num_heads: æ³¨æ„åŠ›å¤´æ•°
        dropout: dropout æ¯”ç‡
    """
    def __init__(self, input_dims=[512, 1536, 64], output_dim=256, num_heads=4, dropout=0.2):
        super().__init__()
        self.num_modalities = len(input_dims)
        self.output_dim = output_dim
        
        # ä¸ºæ¯ä¸ªæ¨¡æ€å­¦ä¹ ä¸€ä¸ªprojectionåˆ°ç»Ÿä¸€ç»´åº¦
        self.projections = nn.ModuleList([
            nn.Sequential(
                nn.Linear(dim, output_dim),
                nn.LayerNorm(output_dim),
                nn.Dropout(dropout),
                nn.LeakyReLU()
            ) for dim in input_dims
        ])
        
        # Multi-head attentionç”¨äºæ¨¡æ€é—´äº¤äº’
        self.attention = nn.MultiheadAttention(
            embed_dim=output_dim,
            num_heads=num_heads,
            batch_first=True,
            dropout=dropout
        )
        
        # å¯å­¦ä¹ çš„query tokenç”¨äºèšåˆ
        self.query_token = nn.Parameter(torch.randn(1, 1, output_dim))
        
        # æœ€ç»ˆè¾“å‡ºæŠ•å½±
        self.output_proj = nn.Sequential(
            nn.Linear(output_dim, output_dim),
            nn.LayerNorm(output_dim),
            nn.Dropout(dropout),
            nn.LeakyReLU()
        )
    
    def forward(self, features_list):
        """
        è¾“å…¥ï¼š
            features_list: [semantic_feat, geo_feat, rsa_feat]
                semantic_feat: [L, 512]
                geo_feat: [L, 1536]
                rsa_feat: [L, 64]
        
        è¾“å‡ºï¼š
            fused: [L, output_dim] (256)
        """
        seq_len = features_list[0].size(0)
        
        # 1. å°†æ‰€æœ‰æ¨¡æ€æŠ•å½±åˆ°ç›¸åŒç»´åº¦
        projected = []
        for i, feat in enumerate(features_list):
            proj_feat = self.projections[i](feat)  # [L, output_dim]
            projected.append(proj_feat.unsqueeze(1))  # [L, 1, output_dim]
        
        # 2. å †å æ‰€æœ‰æ¨¡æ€: [L, num_modalities, output_dim]
        stacked = torch.cat(projected, dim=1)
        
        # 3. ä½¿ç”¨attentionèšåˆè·¨æ¨¡æ€ä¿¡æ¯
        # Query: å¯å­¦ä¹ token, Key/Value: æ‰€æœ‰æ¨¡æ€
        query = self.query_token.expand(seq_len, -1, -1)  # [L, 1, output_dim]
        
        # Attentionè·¨æ¨¡æ€
        fused, attn_weights = self.attention(
            query=query,
            key=stacked,
            value=stacked
        )  # fused: [L, 1, output_dim]
        
        fused = fused.squeeze(1)  # [L, output_dim]
        
        # 4. æœ€ç»ˆæŠ•å½±
        output = self.output_proj(fused)  # [L, output_dim]
        
        return output


# ====================================================================
# T-Netï¼ˆç©ºé—´å˜æ¢ç½‘ç»œï¼‰
# ====================================================================

class Tnet(nn.Module):
    """è®ºæ–‡ä¸­çš„ T-Netï¼Œç”¨äºåæ ‡çš„æ—‹è½¬/å¹³ç§»ä¸å˜æ€§"""
    def __init__(self, input_dim=3):
        super(Tnet, self).__init__()
        self.fc1 = nn.Linear(input_dim, 64)
        self.fc2 = nn.Linear(64, 128)
        self.fc3 = nn.Linear(128, 1024)
        self.fc4 = nn.Linear(1024, 512)
        self.fc5 = nn.Linear(512, 256)
        self.fc6 = nn.Linear(256, 9)  # è¾“å‡º 3x3 å˜æ¢çŸ©é˜µ
        
        self.act = nn.LeakyReLU()
        self.ln1 = nn.LayerNorm(64)
        self.ln2 = nn.LayerNorm(128)
        self.ln3 = nn.LayerNorm(1024)
        self.ln4 = nn.LayerNorm(512)
        self.ln5 = nn.LayerNorm(256)

    def forward(self, x):
        x = self.act(self.ln1(self.fc1(x)))
        x = self.act(self.ln2(self.fc2(x)))
        x = self.act(self.ln3(self.fc3(x)))
        
        # Global pooling
        batch = torch.zeros(x.shape[0], dtype=torch.long, device=x.device)
        x = gep(x, batch=batch)
        
        x = self.act(self.ln4(self.fc4(x)))
        x = self.act(self.ln5(self.fc5(x)))
        x = self.fc6(x)
        
        # åŠ ä¸Šå•ä½çŸ©é˜µä¿è¯åˆå§‹åŒ–ä¸ºæ’ç­‰å˜æ¢
        iden = torch.eye(3, dtype=torch.float32, device=x.device).view(-1)
        x = x + iden
        return x.view(3, 3)


# ====================================================================
# ä½ç½®ç¼–ç 
# ====================================================================

def positional_encoding(d_model, max_len=7000):
    """æ ‡å‡†çš„ Transformer ä½ç½®ç¼–ç """
    position = torch.arange(max_len).unsqueeze(1).float()
    div_term = torch.exp(
        torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model)
    )
    pe = torch.zeros((max_len, d_model))
    pe[:, 0::2] = torch.sin(position * div_term)
    pe[:, 1::2] = torch.cos(position * div_term)
    return pe


# ====================================================================
# ä¸»æ¨¡å‹ï¼šPNBindï¼ˆå®Œå…¨æŒ‰è®ºæ–‡æ¶æ„ï¼‰
# ====================================================================

class benchmark(nn.Module):
    """
    PNBind - æ ¸é…¸ç»“åˆä½ç‚¹é¢„æµ‹æ¨¡å‹
    
    æ¶æ„ï¼ˆä¸¥æ ¼æŒ‰ç…§è®ºæ–‡ Figure 1ï¼‰ï¼š
    1. è¯­ä¹‰åˆ†æ”¯: ESM3 + HMM + PSSM + DSSP â†’ MLP â†’ [L, 512]
    2. å‡ ä½•åˆ†æ”¯: T-Net â†’ PointGNN â†’ [L, 1536]
    3. Late Fusion: ğŸ”´ Attention Fusion â†’ [L, 256]
    4. Decoder: Transformer â†’ Classifier
    
    å‚æ•°ï¼š
        esm_dim: ESM3 è¾“å‡ºç»´åº¦ï¼ˆè®ºæ–‡ä¸­æ˜¯ 1536ï¼‰
        num_classes: åˆ†ç±»æ•°ï¼ˆ2: ç»“åˆ/éç»“åˆï¼‰
        dropout_rate: Dropout æ¯”ç‡
    """
    
    def __init__(self, esm_dim=1536, num_classes=2, dropout_rate=0.2):
        super().__init__()
        
        self.esm_dim = esm_dim
        self.dropout = nn.Dropout(dropout_rate)
        self.LeakyReLU = nn.LeakyReLU()
        
        # ================================================================
        # åˆ†æ”¯1ï¼šå‡ ä½•åˆ†æ”¯ï¼ˆGeometric Branchï¼‰
        # ================================================================
        
        # T-Netï¼šå­¦ä¹ æ—‹è½¬/å¹³ç§»ä¸å˜çš„å˜æ¢
        self.pos_tnet = Tnet(input_dim=3)
        
        # åæ ‡æŠ•å½±åˆ° ESM ç»´åº¦ç©ºé—´
        self.pos_proj = nn.Linear(3, esm_dim)
        
        # PointGNNï¼ˆ3å±‚ï¼‰- è®ºæ–‡ä¸­æ˜ç¡®æåˆ° 3 layers
        self.gnn_layers = nn.ModuleList([
            PointGNNConv(
                mlp_h(esm_dim, esm_dim//2, esm_dim, dropout_rate),
                mlp_f(esm_dim*2, esm_dim, esm_dim, dropout_rate),
                mlp_g(esm_dim, esm_dim, esm_dim, dropout_rate)
            )
            for _ in range(3)
        ])
        
        # ================================================================
        # åˆ†æ”¯2ï¼šè¯­ä¹‰åˆ†æ”¯ï¼ˆSemantic Branchï¼‰
        # ================================================================
        
        # è¾“å…¥: ESM3[1536] + HMM[30] + PSSM[20] + DSSP[13] = 1599
        semantic_input_dim = esm_dim + 30 + 20 + 13  # 1599
        semantic_output_dim = 512
        
        self.semantic_branch = nn.Sequential(
            nn.Linear(semantic_input_dim, 1024),
            nn.LayerNorm(1024),
            nn.Dropout(dropout_rate),
            nn.LeakyReLU(),
            nn.Linear(1024, 768),
            nn.LayerNorm(768),
            nn.Dropout(dropout_rate),
            nn.LeakyReLU(),
            nn.Linear(768, semantic_output_dim),
            nn.LayerNorm(semantic_output_dim),
            nn.Dropout(dropout_rate),
            nn.LeakyReLU()
        )
        
        # ================================================================
        # åˆ†æ”¯3ï¼šRSA
        # ================================================================
        
        rsa_output_dim = 64
        self.rsa_branch = nn.Sequential(
            nn.Linear(1, 32),
            nn.LeakyReLU(),
            nn.Linear(32, rsa_output_dim),
            nn.LeakyReLU()
        )
        
        # ================================================================
        # ğŸ”´ Late Fusion Layer (ä½¿ç”¨æ³¨æ„åŠ›èåˆ)
        # ================================================================
        
        fusion_output_dim = 256
        
        # ğŸ”´ æ–°ç‰ˆï¼šä½¿ç”¨ AttentionFusion æ›¿ä»£ç®€å•çš„ MLP
        self.fusion_layer = AttentionFusion(
            input_dims=[semantic_output_dim, esm_dim, rsa_output_dim],  # [512, 1536, 64]
            output_dim=fusion_output_dim,  # 256
            num_heads=4,
            dropout=dropout_rate
        )
        
        # ================================================================
        # Transformer Decoder
        # ================================================================
        
        self.decoder_layer = nn.TransformerDecoderLayer(
            d_model=fusion_output_dim,
            nhead=8,  # å¤šå¤´æ³¨æ„åŠ›
            dim_feedforward=1024,
            dropout=dropout_rate,
            activation='gelu'
        )
        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=2)
        
        # ================================================================
        # åˆ†ç±»å¤´
        # ================================================================
        
        self.classifier = nn.Sequential(
            nn.Linear(fusion_output_dim, 128),
            nn.LeakyReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(128, num_classes)
        )
        
        # ================================================================
        # åˆå§‹åŒ–
        # ================================================================
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, point_graph):
        """
        å‰å‘ä¼ æ’­
        
        è¾“å…¥ï¼š
            point_graph: torch_geometric.data.Data å¯¹è±¡
                - x_esm3: [L, 1536] ESM3 ç‰¹å¾
                - hmm: [L, 30] HMM ç‰¹å¾
                - pssm: [L, 20] PSSM ç‰¹å¾
                - secondary: [L, 13] DSSP äºŒçº§ç»“æ„
                - asa: [L] æº¶å‰‚å¯åŠæ€§
                - pos: [L, 3] CÎ± åæ ‡
                - edge_index: [2, E] è¾¹ç´¢å¼•
        
        è¾“å‡ºï¼š
            out: [L, 2] æ¯ä¸ªæ®‹åŸºçš„é¢„æµ‹åˆ†æ•°
            min_len: int æœ‰æ•ˆæ®‹åŸºæ•°é‡
        """
        
        # ============================================================
        # æå–è¾“å…¥ç‰¹å¾
        # ============================================================
        
        edge_index = point_graph.edge_index
        pos = point_graph.pos  # [L, 3]
        
        x_esm = point_graph.x_esm3  # [L, 1536]
        hmm = point_graph.hmm  # [L, 30]
        pssm = point_graph.pssm  # [L, 20]
        secondary = point_graph.secondary  # [L, 13]
        asa = point_graph.asa  # [L]
        
        # ============================================================
        # é•¿åº¦å¯¹é½ï¼ˆé˜²æ­¢ç»´åº¦ä¸åŒ¹é…ï¼‰
        # ============================================================
        
        min_len = min(
            pos.size(0),
            x_esm.size(0),
            hmm.size(0),
            pssm.size(0),
            secondary.size(0),
            asa.size(0)
        )
        
        pos = pos[:min_len]
        x_esm = x_esm[:min_len]
        hmm = hmm[:min_len]
        pssm = pssm[:min_len]
        secondary = secondary[:min_len]
        asa = asa[:min_len]
        edge_mask = (edge_index[0] < min_len) & (edge_index[1] < min_len)
        edge_index = edge_index[:, edge_mask]
        
        # ============================================================
        # åˆ†æ”¯1ï¼šå‡ ä½•åˆ†æ”¯
        # ============================================================
        
        # 1.1 T-Net ç©ºé—´å˜æ¢
        T = self.pos_tnet(pos)  # [3, 3]
        pos_transformed = torch.matmul(pos, T)  # [L, 3]
        pos_normalized = F.layer_norm(pos_transformed, (3,))
        
        # 1.2 åæ ‡åµŒå…¥
        pos_embed = self.pos_proj(pos_normalized)  # [L, 1536]
        
        # 1.3 PointGNNï¼ˆ3å±‚ï¼‰
        geo_feat = pos_embed
        for layer in self.gnn_layers:
            geo_feat = self.LeakyReLU(layer(geo_feat, pos_embed, edge_index))
        # geo_feat: [L, 1536]
        
        # ============================================================
        # åˆ†æ”¯2ï¼šè¯­ä¹‰åˆ†æ”¯
        # ============================================================
        
        # 2.1 æ‹¼æ¥åºåˆ—å’Œè¿›åŒ–ç‰¹å¾
        semantic_input = torch.cat([x_esm, hmm, pssm, secondary], dim=1)  # [L, 1599]
        
        # 2.2 MLP å¤„ç†
        semantic_feat = self.semantic_branch(semantic_input)  # [L, 512]
        
        # ============================================================
        # åˆ†æ”¯3ï¼šRSA
        # ============================================================
        
        rsa_feat = self.rsa_branch(asa.unsqueeze(1))  # [L, 64]
        
        # ============================================================
        # ğŸ”´ Late Fusion (ä½¿ç”¨æ³¨æ„åŠ›èåˆ)
        # ============================================================
        
        # ä½¿ç”¨ AttentionFusion æ›¿ä»£ç®€å•çš„ concat + MLP
        fused = self.fusion_layer([semantic_feat, geo_feat, rsa_feat])  # [L, 256]
        
        # ============================================================
        # Transformer Decoder
        # ============================================================
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pe = positional_encoding(fused.size(1), min_len).to(fused.device)
        fused_with_pe = fused + pe[:min_len, :fused.size(1)]
        
        # Transformer éœ€è¦ [L, B, D] æ ¼å¼
        fused_t = fused_with_pe.unsqueeze(1)  # [L, 1, 256]
        decoded = self.decoder(fused_t, fused_t).squeeze(1)  # [L, 256]
        
        # ============================================================
        # åˆ†ç±»
        # ============================================================
        
        out = self.classifier(decoded)  # [L, 2]
        
        return out, min_len


# ====================================================================
# å‘åå…¼å®¹ï¼ˆå¦‚æœå…¶ä»–ä»£ç è¿˜åœ¨ç”¨æ—§åå­—ï¼‰
# ====================================================================

# è¿™æ · train.py é‡Œçš„ model = benchmark(...) ä»ç„¶å¯ä»¥å·¥ä½œ